{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ffc30c",
   "metadata": {},
   "source": [
    "## 核岭回归课堂演讲稿（3部分，口述版）\n",
    "\n",
    "**Kernel Ridge Regression Class Presentation (3 Sections, Full Script)**\n",
    "\n",
    "---\n",
    "\n",
    "### 第一部分：概述与原理\n",
    "\n",
    "**Part 1: Overview & Principle**\n",
    "（约4分钟）\n",
    "\n",
    "**中文口述稿：**\n",
    "大家好，今天我要和大家分享的是**核岭回归**，英文叫 **Kernel Ridge Regression**，简称 **KRR**。\n",
    "在进入具体算法之前，我们先回顾两个核心背景：岭回归和核方法。\n",
    "\n",
    "首先是**岭回归**。\n",
    "岭回归是在线性回归的基础上加入了一个L2正则化项，这个项的作用就是惩罚模型的参数过大，从而减少过拟合风险。它的损失函数形式是：\n",
    "\n",
    "$$\n",
    "\\min_w \\|y - Xw\\|^2 + \\lambda \\|w\\|^2\n",
    "$$\n",
    "\n",
    "其中 $\\lambda$ 就是正则化参数，它越大，惩罚力度越强，模型越保守。\n",
    "\n",
    "接下来是**核方法**。\n",
    "在现实问题中，很多数据关系并不是线性的，比如正弦曲线、圆形分布等。核方法的思想是：通过一个核函数，把原来的输入数据隐式地映射到一个高维空间，在这个空间里，原本复杂的非线性关系有可能变成线性关系。这样我们就可以用线性方法去解决非线性问题。\n",
    "常见的核函数有：\n",
    "\n",
    "* **线性核（Linear）**：不做映射，直接内积。\n",
    "* **多项式核（Polynomial）**：用多项式来组合特征。\n",
    "* **RBF核（Radial Basis Function）**：用高斯函数衡量相似度，常用于非线性拟合。\n",
    "* **Sigmoid核**：类似神经元的激活函数。\n",
    "\n",
    "**核岭回归**就是把岭回归和核方法结合起来，在高维空间做岭回归。它的目标函数是：\n",
    "\n",
    "$$\n",
    "\\min_{\\alpha} \\| y - K \\alpha \\|^2 + \\lambda \\alpha^T K \\alpha\n",
    "$$\n",
    "\n",
    "这里的 $K$ 是核矩阵，它的每个元素是两个样本之间的核函数值；$\\alpha$ 是对偶系数；$\\lambda$ 控制正则化强度。\n",
    "\n",
    "这种方法有两个好处：\n",
    "\n",
    "1. 能处理复杂的非线性关系。\n",
    "2. 有正则化机制，能避免过拟合。\n",
    "\n",
    "**English Script:**\n",
    "Hello everyone, today I’ll talk about **Kernel Ridge Regression**, or **KRR**.\n",
    "Before diving into the details, let’s review two important concepts: ridge regression and kernel methods.\n",
    "\n",
    "First, **ridge regression** adds an L2 regularization term to the least squares loss. This penalizes large parameter values, which helps prevent overfitting. The loss function is:\n",
    "\n",
    "$$\n",
    "\\min_w \\|y - Xw\\|^2 + \\lambda \\|w\\|^2\n",
    "$$\n",
    "\n",
    "where $\\lambda$ controls the strength of regularization.\n",
    "\n",
    "Next, **kernel methods**. Many real-world relationships are nonlinear. Kernel methods map the input data into a high-dimensional space—implicitly—through a kernel function, where the data might become linearly separable. Common kernels include:\n",
    "\n",
    "* **Linear**: inner product without mapping.\n",
    "* **Polynomial**: polynomial combinations of features.\n",
    "* **RBF**: Gaussian similarity, very powerful for nonlinear fitting.\n",
    "* **Sigmoid**: similar to neural network activation functions.\n",
    "\n",
    "KRR combines these two: ridge regression in a high-dimensional space defined by the kernel. The objective is:\n",
    "\n",
    "$$\n",
    "\\min_{\\alpha} \\| y - K \\alpha \\|^2 + \\lambda \\alpha^T K \\alpha\n",
    "$$\n",
    "\n",
    "where $K$ is the kernel matrix, $\\alpha$ are the dual coefficients, and $\\lambda$ is the regularization strength.\n",
    "This gives us **nonlinear modeling power with regularization control**.\n",
    "\n",
    "---\n",
    "\n",
    "### 第二部分：实现与核心模块\n",
    "\n",
    "**Part 2: Implementation & Core Modules**\n",
    "（约4分钟）\n",
    "\n",
    "**中文口述稿：**\n",
    "接下来我们看看实现细节，我们的代码主要由三个文件组成。\n",
    "\n",
    "第一个是 **`kernels.py`**，这里定义了四种核函数。以**RBF核**为例，它的公式是：\n",
    "\n",
    "$$\n",
    "K(x, x') = \\exp(-\\gamma \\|x - x'\\|^2)\n",
    "$$\n",
    "\n",
    "在代码中，我们用 NumPy 向量化计算，避免了双重for循环，大大提高了计算效率。其他的核函数，比如线性核、多项式核、Sigmoid核，也都在这里实现。\n",
    "\n",
    "第二个是 **`kernel_ridge.py`**，核心类是 `KernelRidge`。它有几个关键方法：\n",
    "\n",
    "* `__init__`：初始化模型，指定核类型、正则化参数alpha、gamma、degree等。\n",
    "* `fit(X, y)`：先计算核矩阵 $K$，然后解线性方程组 $(K + n\\alpha I)\\alpha = y$，得到对偶系数。\n",
    "* `predict(X)`：计算测试点和训练点的核矩阵，然后与对偶系数相乘，得到预测结果。\n",
    "\n",
    "第三个是 **`example_usage.py`**，这是一个示例文件。\n",
    "这里我们首先生成一批非线性数据，比如：\n",
    "\n",
    "$$\n",
    "y = \\sin(x) + \\text{噪声}\n",
    "$$\n",
    "\n",
    "然后用RBF核训练模型，画出预测曲线。同时我们也比较了不同核函数的预测效果，比如线性核就很难拟合正弦曲线，而RBF核表现得非常好。\n",
    "\n",
    "**English Script:**\n",
    "Let’s look at the implementation. Our code has three main files.\n",
    "\n",
    "First, **`kernels.py`** defines four kernels. For example, the **RBF kernel**:\n",
    "\n",
    "$$\n",
    "K(x, x') = \\exp(-\\gamma \\|x - x'\\|^2)\n",
    "$$\n",
    "\n",
    "We use NumPy vectorization for efficient computation. Other kernels—linear, polynomial, sigmoid—are also implemented here.\n",
    "\n",
    "Second, **`kernel_ridge.py`** contains the core `KernelRidge` class. Key methods:\n",
    "\n",
    "* `__init__`: initializes the model with kernel type, alpha, gamma, degree, etc.\n",
    "* `fit(X, y)`: computes the kernel matrix $K$ and solves $(K + n\\alpha I)\\alpha = y$ for the dual coefficients.\n",
    "* `predict(X)`: computes the kernel matrix between test and train data and multiplies by the dual coefficients to get predictions.\n",
    "\n",
    "Third, **`example_usage.py`** shows a demo. We generate nonlinear data:\n",
    "\n",
    "$$\n",
    "y = \\sin(x) + \\text{noise}\n",
    "$$\n",
    "\n",
    "Train with the RBF kernel, plot predictions, and compare kernels. Linear kernels fail to capture sine waves, while RBF does well.\n",
    "\n",
    "---\n",
    "\n",
    "### 第三部分：实验与总结\n",
    "\n",
    "**Part 3: Experiments & Conclusion**\n",
    "（约4分钟）\n",
    "\n",
    "**中文口述稿：**\n",
    "在实验部分，我们的 `example_usage.py` 展示了完整过程。\n",
    "\n",
    "首先是数据生成：我们创建了1000个点，x在0到20之间，y是正弦函数加上随机噪声。这样数据的非线性特征非常明显。\n",
    "\n",
    "然后，我们用RBF核进行训练。RBF核有一个超参数gamma，它控制高斯分布的宽度。gamma太大，模型容易过拟合；太小，模型会欠拟合。在实验中我们选取了0.5作为gamma。\n",
    "\n",
    "训练后，我们画出预测曲线，可以看到红色的预测线几乎和绿色的真实曲线重合，这说明模型拟合得非常好。\n",
    "\n",
    "我们还比较了不同核的表现：\n",
    "\n",
    "* 线性核：只能拟合大致趋势，无法捕捉正弦的波动。\n",
    "* 多项式核：拟合能力比线性好，但容易在波峰波谷处出现偏差。\n",
    "* RBF核：效果最佳，几乎重合。\n",
    "* Sigmoid核：在某些段落表现不错，但整体拟合不如RBF。\n",
    "\n",
    "最后，总结一下核岭回归的优缺点：\n",
    "优点：\n",
    "\n",
    "1. 能处理非线性数据。\n",
    "2. 正则化抑制过拟合。\n",
    "   缺点：\n",
    "3. 样本数很大时，计算核矩阵会很耗内存。\n",
    "4. 参数选择（如gamma、alpha）需要交叉验证。\n",
    "\n",
    "**English Script:**\n",
    "In the experiments, `example_usage.py` shows the full pipeline.\n",
    "\n",
    "We generate 1000 points, x from 0 to 20, y as a sine function plus random noise—making the nonlinearity obvious.\n",
    "\n",
    "We train with the RBF kernel. The gamma parameter controls the Gaussian width: too large risks overfitting, too small underfits. We use gamma = 0.5.\n",
    "\n",
    "After training, the predicted curve almost overlaps with the true curve—showing strong fitting ability.\n",
    "\n",
    "Kernel comparison results:\n",
    "\n",
    "* Linear: captures only the trend, misses sine oscillations.\n",
    "* Polynomial: better than linear but deviates at peaks and troughs.\n",
    "* RBF: best performance, near-perfect fit.\n",
    "* Sigmoid: good in some segments but not overall.\n",
    "\n",
    "Summary of pros and cons:\n",
    "**Pros**:\n",
    "\n",
    "1. Handles nonlinear data.\n",
    "2. Regularization prevents overfitting.\n",
    "   **Cons**:\n",
    "3. Computing kernel matrix is costly for large datasets.\n",
    "4. Parameter tuning (gamma, alpha) requires cross-validation.\n",
    "\n",
    "---\n",
    "\n",
    "我可以帮你把这份**12分钟口述稿配合你的代码绘图做成PPT**，这样每部分讲的时候有可视化曲线对照，课堂效果会更好。\n",
    "你要我帮你做这个PPT版本吗？这样讲起来会更直观。\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
